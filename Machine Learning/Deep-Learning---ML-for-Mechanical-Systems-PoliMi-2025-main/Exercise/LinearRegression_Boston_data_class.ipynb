{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edeaeaca-83f1-4f78-ba13-c82abc3973aa",
   "metadata": {},
   "source": [
    "# Linear Regression with the Boston Housing Dataset\n",
    "**Date:** January 25, 2025  \n",
    "**Author:** Dario Piga  \n",
    "\n",
    "In this notebook, we will implement a multivariate linear regression model using PyTorch to predict housing prices in Boston. We will use multiple features from the dataset to build our model, allowing us to examine how various factors, such as the number of rooms, crime rate, pupil-teacher ratio, and the economic status of the population, influence home prices.\n",
    "\n",
    "## The Boston Housing Dataset\n",
    "\n",
    "The \"Boston Housing\" dataset contains information collected by the U.S Census Service concerning the Boston, Massachusetts area. This dataset is widely used as a benchmark for regression algorithms and includes the following features:\n",
    "\n",
    "- `CRIM`: Per capita crime rate by town\n",
    "- `ZN`: Proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- `INDUS`: Proportion of non-retail business acres per town\n",
    "- `CHAS`: Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "- `NOX`: Nitric oxides concentration (parts per 10 million)\n",
    "- `RM`: Average number of rooms per dwelling\n",
    "- `AGE`: Proportion of owner-occupied units built prior to 1940\n",
    "- `DIS`: Weighted distances to five Boston employment centers\n",
    "- `RAD`: Index of accessibility to radial highways\n",
    "- `TAX`: Full-value property-tax rate per 10,000\n",
    "- `PTRATIO`: Pupil-teacher ratio by town\n",
    "- `B`: 1000(Bk - 0.63)$^2$ where Bk is the proportion of blacks by town. This variable has been criticized as unethical in its formulation.\n",
    "- `LSTAT`: % lower status of the population\n",
    "- `MEDV`: Median value of owner-occupied homes in 1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c5ddd-6034-4696-a60f-09ecce04fcb4",
   "metadata": {},
   "source": [
    "## Selected Variables for Analysis\n",
    "\n",
    "In this exercise, we will use a subset of features from the Boston Housing Dataset to develop our regression model. Below is a detailed description of each feature that will be included in our analysis:\n",
    "\n",
    "- `CRIM`: This feature represents the per capita crime rate by town. Higher crime rates can negatively impact housing prices due to perceived safety concerns.\n",
    "\n",
    "- `RM`: The average number of rooms per dwelling. Generally, a higher number of rooms indicates more space, which can positively influence the housing price.\n",
    "\n",
    "- `PTRATIO`: Pupil-teacher ratio by town. A lower pupil-teacher ratio is often associated with better educational resources, making the area more attractive to families with children.\n",
    "\n",
    "- `LSTAT`: Percentage of lower status of the population. Higher percentages can indicate socioeconomic challenges, which may lower property values.\n",
    "\n",
    "These variables have been chosen because they provide insights into different aspects of residential areas that can directly affect housing prices, such as safety, space, education, and socioeconomic status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6da6d9-f406-4bb9-90f3-04375876b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56857db-75a3-4377-bf5e-476b8bb4ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and prepare the dataset\n",
    "\n",
    "# URL for the Boston Housing dataset\n",
    "data_url = \"housing.xls\"\n",
    "\n",
    "# Attempt to read the dataset via Pandas\n",
    "try:\n",
    "    \n",
    "    column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "    df = pd.read_csv('housing.xls', header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "    print(raw_df.head(5))\n",
    "    \n",
    "    print(\"Processed DataFrame:\")\n",
    "    print(df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error loading or processing the dataset:\", e)\n",
    "\n",
    "\n",
    "print(f\"Datset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d927c-8237-4f80-9126-601d40b3990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific features and plots (TO BE DONE)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3760bf-48a4-45b4-ac3c-4ec550718397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific features and plots (SOLUTION)\n",
    "features = ['CRIM', 'RM', 'PTRATIO', 'LSTAT']\n",
    "X = df[features]\n",
    "y = df['MEDV']\n",
    "\n",
    "# Define units for clarity\n",
    "units = {\n",
    "    'CRIM': 'per capita crime rate by town',\n",
    "    'RM': 'average number of rooms per dwelling',\n",
    "    'PTRATIO': 'pupil-teacher ratio by town',\n",
    "    'LSTAT': '% lower status of the population',\n",
    "    'MEDV': 'Median value of owner-occupied homes ($1000s)'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for f in features:\n",
    "    plt.figure()\n",
    "    plt.hist(df[f], bins = 20)\n",
    "    plt.title(f'Histogram of feature {f}')\n",
    "    plt.xlabel(units[f])\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(y, bins = 20)\n",
    "plt.title(f\"Histogram of target variable: MEDV\")\n",
    "plt.xlabel(units['MEDV'])\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a9019-4242-45eb-a61b-b47b1cc3fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2629c-f203-4b6f-9694-fd6453f02f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets (TO BE DONE)\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f630f-4b38-4839-96f1-a1b4c9be21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets (SOLUTION)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features and output to have zero mean and unitary std\n",
    "\n",
    "# Normalize training and test dataset. Note that training and test datasets are normalized using the same mean and std \n",
    "X_mean = X_train.mean(axis = 0)\n",
    "X_std = X_train.std(axis = 0)\n",
    "X_train = (X_train - X_mean)/X_std \n",
    "X_test = (X_test - X_mean)/X_std\n",
    "\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std()\n",
    "y_train = (y_train - y_mean)/y_std \n",
    "y_test = (y_test - y_mean)/y_std\n",
    "\n",
    "# sanity check:\n",
    "print(f\"Training features: \\n Mean:\\n {X_train.mean(axis = 0)} \\n Std:\\n {X_train.std(axis = 0)}\\n\")\n",
    "print(f\"Training target: \\n Mean:\\n {y_train.mean():.2f} \\n Std:\\n {y_train.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc46edb-7a9b-4841-9abf-bd9ee51836e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datasets to tensors (TO BE DONE)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c1da9-46ae-4211-9493-13b00e5d76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datasets to tensors (solution)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype = torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype = torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype = torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype = torch.float32)\n",
    "\n",
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ee2c8-7522-4144-812b-72ebc9cf7e1a",
   "metadata": {},
   "source": [
    "# Creat a linear model in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd257859-224f-4c37-ae89-59e458580e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model (TBD)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84334cd4-49c2-4307-91ba-c4f21ade528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model (solution)\n",
    "model = nn.Linear(X.shape[1], 1) # define linear model with 4 features and 1 output variable\n",
    "print(f\"Model structure: {model}\")\n",
    "\n",
    "for name, params in model.named_parameters():\n",
    "    print(f\"parameter name: {name}. Value {params.data}\")\n",
    "\n",
    "# check what model provides:\n",
    "y_hat = model(X_train_tensor)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe02bc2-d3d0-475b-935c-0d97bbacd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "def myMSE(y_hat, y_train):\n",
    "    loss = torch.mean((y_hat.squeeze() - y_train.squeeze())**2)\n",
    "    return loss\n",
    "    \n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49b743-9bd6-4ce3-973b-7b49b314ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop (TBD)\n",
    "\n",
    "...\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0375996-f89b-41ad-84aa-5361adf3c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop (SOLUTION)\n",
    "max_epochs = 1000\n",
    "for it in range(max_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(X_train_tensor)\n",
    "    loss = myMSE(y_hat, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if it % 5 == 0:\n",
    "        print(f\"Iteration: {it}. Loss: {loss.item() :3f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a19ed-0135-4f9a-9da7-5a4b9aaf9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For linear models, model interpration is possible and easy. Let us look at the values of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e58d1-735e-4372-ac24-65a2691bf26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0ebb7-97fc-4eec-8e0f-3b4dc523af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess final results (TBD)\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b4fc6-be59-4feb-b638-b796926842bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess final results (solution)\n",
    "\n",
    "def assess_results(model, X, y, data_type):\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(X)\n",
    "        \n",
    "        # Prediction and plotting\n",
    "        plt.figure(figsize = (8, 8))\n",
    "        plt.plot(y_hat.numpy(), 'r-', label='Predicted output')\n",
    "        plt.plot(y.numpy(), 'b-', label='True output')\n",
    "        plt.title(f'Predicted vs Estimated output: {data_type} dataset')  # Fixed f-string\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Prediction and plotting\n",
    "        plt.figure(figsize = (5, 5))\n",
    "        plt.scatter(y_hat.numpy(), y.numpy())\n",
    "        plt.plot(np.arange(-3,3), np.arange(-3, 3))\n",
    "        plt.xlabel('Predicted output')\n",
    "        plt.ylabel('True output')\n",
    "        plt.title(f'Predicted vs Estimated output: {data_type} dataset')  # Fixed f-string\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # RMSE calculation\n",
    "        mse = torch.mean((y_hat - y) ** 2)\n",
    "        rmse = torch.sqrt(mse)\n",
    "        \n",
    "\n",
    "        # R2 calculation\n",
    "        total_variance = torch.var(y)\n",
    "        residual_variance = torch.mean((y_hat - y) ** 2)\n",
    "        R2 = 1 - residual_variance / total_variance\n",
    "\n",
    "    return rmse, R2 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad2fb3-88af-4e3e-8912-7fa8a2120bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess results in training\n",
    "rmse, R2 = assess_results(model, X_train_tensor, y_train_tensor.view(-1,1), data_type = 'train')\n",
    "print('Training results')\n",
    "print(f\"rmse = {rmse}. R2 = {R2:.3f}\")\n",
    "\n",
    "\n",
    "# Assess results in test\n",
    "rmse, R2 = assess_results(model, X_test_tensor, y_test_tensor.view(-1,1), data_type = 'test')\n",
    "print('Training results')\n",
    "print(f\"rmse = {rmse}. R2 = {R2:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
