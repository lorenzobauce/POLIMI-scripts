{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dd85305-72bb-498b-80ef-3ecac21d0883",
   "metadata": {},
   "source": [
    "# Logistic Regression with the Titanic Survival Dataset\n",
    "**Date:** January 25, 2025  \n",
    "**Author:** Dario Piga  \n",
    "\n",
    "In this notebook, we will implement a logistic regression model using `pytorch` to predict survival on the Titanic. Our goal is to understand how various factors such as passenger class, gender, age, and fare contribute to the likelihood of survival. By applying logistic regression, we will model these relationships to predict binary outcomes, specifically, whether a passenger survived or not.\n",
    "\n",
    "## The Titanic Survival Dataset\n",
    "\n",
    "The Titanic dataset is a historical dataset that contains data on the passengers aboard the RMS Titanic, which famously sank on its maiden voyage in 1912. This dataset includes the following features:\n",
    "\n",
    "- `survived`: Survival (0 = No, 1 = Yes)\n",
    "- `pclass`: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "- `sex`: Gender (male or female)\n",
    "- `age`: Age in years\n",
    "- `fare`: Passenger fare\n",
    "- and others not used in this exercise\n",
    "  \n",
    "We will explore the data, perform necessary preprocessing steps, and build a logistic regression model to predict whether a passenger survived based on their features. We will also evaluate our model's performance using various metrics to understand its effectiveness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed468c-a4c4-4dbd-b089-59c72281d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9861d-9478-425e-9ec0-c3dd4e87dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Select specific columns\n",
    "features = ['pclass', 'sex', 'age', 'fare']\n",
    "df = df[features + ['survived']]\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc94c4b-34b8-4ce2-b284-7c05f0a8db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gender into binary variable (0 or 1)\n",
    "df['sex'] = df['sex'].map({'female': 0, 'male': 1})\n",
    "# Selecting specific features\n",
    "X = df[features]\n",
    "y = df['survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8234907-25de-47a1-ae06-a98da5e8ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your data (TBD)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9e010-f5b9-420b-811a-d426a5f9553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your data (solution)\n",
    "\n",
    "for f in features:\n",
    "    plt.figure(figsize= (3, 3))\n",
    "    plt.hist(df[f], bins = 20)\n",
    "    plt.title(f'Histogram of feature {f}')\n",
    "    plt.xlabel(f)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(y, bins = 20)\n",
    "plt.title(f\"Histogram of target variable: MEDV\")\n",
    "plt.xlabel('Survived')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f18fb5-eb63-440b-a16b-5bce26a33743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets and normalize (TBD)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d4920-1b81-495e-b2b8-46c8dc31845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets and normalize (solution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features and output to have zero mean and unitary std\n",
    "\n",
    "# Normalize training and test dataset. Note that training and test datasets are normalized using the same mean and std \n",
    "X_mean = X_train.mean(axis = 0)\n",
    "X_std = X_train.std(axis = 0)\n",
    "X_train = (X_train - X_mean)/X_std \n",
    "X_test = (X_test - X_mean)/X_std\n",
    "\n",
    "\n",
    "# sanity check:\n",
    "print(f\"Training features: \\n Mean:\\n {X_train.mean(axis = 0)} \\n Std:\\n {X_train.std(axis = 0)}\\n\")\n",
    "print(f\"Training target: \\n Mean:\\n {y_train.mean():.2f} \\n Std:\\n {y_train.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093aa298-c2a9-4b94-a7c6-1408b8d99701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datasets to tensors\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype = torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype = torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype = torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56870500-4ed3-459d-9611-c3f929b501a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression model in Pytorch (TBD)\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c82f6e-8e1f-41e4-a3f8-241df341305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # Linear layer\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Applying the linear layer and then the sigmoid function\n",
    "        outputs = self.sigmoid(self.linear(x))\n",
    "        return outputs\n",
    "\n",
    "model = LogisticRegressionModel(input_dim = X.shape[1])\n",
    "\n",
    "print(f\"Model structure: {model}\")\n",
    "\n",
    "for name, params in model.named_parameters():\n",
    "    print(f\"parameter name: {name}. Value {params.data}\")\n",
    "\n",
    "# check what model provides:\n",
    "y_hat = model(X_train_tensor)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42eb7e-1bca-464a-9dc0-65061af68ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function for binary classification\n",
    "criterion = nn.BCELoss() # Binary cross entropy\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80213a2e-e9fb-4b6e-b252-f2db31387c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop (TBD)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f33ca-5531-42d0-9871-5f8bf7541057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop (solution)\n",
    "max_epochs = 1000\n",
    "for it in range(max_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    p_hat = model(X_train_tensor)\n",
    "    loss = criterion(p_hat, y_train_tensor.reshape(-1,1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if it % 5 == 0:\n",
    "        y_hat = p_hat > 0.5\n",
    "        accuracy = (y_hat == y_train_tensor.view(-1,1)).float().sum()/y_hat.shape[0]\n",
    "        print(f\"Iteration: {it}. Loss: {loss.item() :3f}. Accuracy: {accuracy.item()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385537d-4699-4a0d-8202-e61d073cb24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess performance (TBD)\n",
    "\n",
    "def assess_results(model, X, y, data_type):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "\n",
    "        # Compute accuracy\n",
    "        ...\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        \n",
    "        TP = ...  # True Positive\n",
    "        TN = ...  # True Negative\n",
    "        FP = ...  # False Positive\n",
    "        FN = ...  # False Negative\n",
    "\n",
    "        # Print confusion matrix results\n",
    "        print(f\"Accuracy: {accuracy*100:.3f} % \")\n",
    "        print(f\"Confusion Matrix for {data_type} Data:\")\n",
    "        print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f21c91-7a2e-46f3-878a-0709da530364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess performance (solution)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def assess_results(model, X, y, data_type):\n",
    "    with torch.no_grad():\n",
    "        p_hat = model(X).squeeze()  # Get the predicted probabilities\n",
    "        y_hat = (p_hat > 0.5).float()  # Convert probabilities to 0 or 1 based on threshold\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy = torch.mean((y_hat == y).float()).item()  # Convert boolean to float and calculate mean\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        TP = torch.sum((y_hat == 1) & (y == 1)).item()  # True Positive\n",
    "        TN = torch.sum((y_hat == 0) & (y == 0)).item()  # True Negative\n",
    "        FP = torch.sum((y_hat == 1) & (y == 0)).item()  # False Positive\n",
    "        FN = torch.sum((y_hat == 0) & (y == 1)).item()  # False Negative\n",
    "\n",
    "        # Print confusion matrix results\n",
    "        print(f\"Accuracy: {accuracy*100:.3f} % \")\n",
    "        print(f\"Confusion Matrix for {data_type} Data:\")\n",
    "        print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad4720-2be5-4b70-974f-f13e34e7b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess results in training\n",
    "print('Training results')\n",
    "\n",
    "assess_results(model, X_train_tensor, y_train_tensor, data_type = 'train')\n",
    "#print(f\"rmse = {rmse}. R2 = {R2:.3f}\")\n",
    "\n",
    "\n",
    "# Assess results in test\n",
    "print('Test results')\n",
    "\n",
    "assess_results(model, X_test_tensor, y_test_tensor, data_type = 'test')\n",
    "#print(f\"rmse = {rmse}. R2 = {R2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99622e1-a58d-42c4-b08d-301cfbb0e1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283a4a0-b911-4d0e-b3cc-f078dcc8422a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
